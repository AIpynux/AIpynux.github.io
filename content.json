{"meta":{"title":"红发","subtitle":"常怀敬畏之心","description":"学习Java后端开发中","author":"红发","url":"https://AIpynux.github.io"},"pages":[{"title":"分类","date":"2019-02-04T04:04:10.000Z","updated":"2019-02-19T09:51:59.160Z","comments":false,"path":"categories/index.html","permalink":"https://AIpynux.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-02-04T04:00:38.000Z","updated":"2019-02-19T09:52:18.780Z","comments":false,"path":"tags/index.html","permalink":"https://AIpynux.github.io/tags/index.html","excerpt":"","text":""},{"title":"个人简介","date":"2019-02-19T16:40:27.511Z","updated":"2019-02-19T16:40:27.483Z","comments":true,"path":"about/index.html","permalink":"https://AIpynux.github.io/about/index.html","excerpt":"","text":"爱折腾，喜欢Linux，Vim预备党，正努力学习Java后端技术的CUMTer，95后。"},{"title":"朋友们","date":"2019-01-21T14:46:30.048Z","updated":"2019-01-21T14:46:30.020Z","comments":true,"path":"friends/index.html","permalink":"https://AIpynux.github.io/friends/index.html","excerpt":"","text":"各位大佬想交换友链的话可以在下方留言，必须要有名称、头像链接、和至少一个标签哦～ 名称: 红发头像: https://github.com/hgneer/Resource_of_Blogs/raw/master/Shanks.jpg网址: https://hgneer.github.io/标签: 爱折腾头像背景色值: #99001C"}],"posts":[{"title":"在MarkDown文件中插入可显示的尖括号","slug":"在MarkDown文件中插入可显示的尖括号","date":"2019-05-11T03:12:35.000Z","updated":"2019-05-11T03:24:15.765Z","comments":true,"path":"2019/05/11/在MarkDown文件中插入可显示的尖括号/","link":"","permalink":"https://AIpynux.github.io/2019/05/11/在MarkDown文件中插入可显示的尖括号/","excerpt":"","text":"在MarkDown文件中如果直接输入&lt;&gt;代表尖括号，实际上会显示不出来。因为这样的尖括号会\\被认为是html标签标记而不显示。事实上要让MarkDown文件正常显示尖括号需要使用转义符12&amp;lt;对应&lt;&amp;gt;对应&gt;","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"MarkDown","slug":"MarkDown","permalink":"https://AIpynux.github.io/tags/MarkDown/"}]},{"title":"恢复Vim文件","slug":"恢复Vim文件","date":"2019-05-11T02:24:17.000Z","updated":"2019-05-11T03:17:49.760Z","comments":true,"path":"2019/05/11/恢复Vim文件/","link":"","permalink":"https://AIpynux.github.io/2019/05/11/恢复Vim文件/","excerpt":"","text":"要想在发生异常断电后恢复断电前没来的急保存的Vim文件，需要事先做到以下几点： 在~/.vimrc配置文件中设置： 1set swapfile 这行代码设置后，使得Vim每次编辑文件时会自动创建一个名为”.&lt;fileName&gt;.swp”的交换文\\件，用于自动备份正在编辑的Vim文件内容。如果正常编辑完成，退出Vim时，Vim会自动删除\\这个交换文件。但是如果编辑过程中发生异常中断，这个文件就不会自动删除，而是可以用于恢\\复我们的Vim文件。而且，一般情况下，当我们在去编辑这个发生过内容丢失的Vim文件时，Vim也\\会询问我们是否选择从交换文件中恢复文件。 确保Vim自动备份的配置无误：12set updatetime = 40000set updatecount = 400 updatetime是自动备份到交换文件的间隔时间(ms)，updatecount是自动备份到交换文件的间隔字符数。\\所以，这两个变量的值一定不能设置为0，否则不会自动备份到交换文件。 这样以后，当在编辑过程中发生异常中断后，我们可以通过以下命令修复文件：1vim -r &lt;fileName&gt; 最后，当我们确保文件恢复无误后，可以选择手动删除掉交换文件”.&lt;fileName&gt;.swp”。","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://AIpynux.github.io/tags/Vim/"}]},{"title":"Ubuntu16.04下误删chromium书签恢复","slug":"Ubuntu16.04下误删chromium书签恢复","date":"2019-05-05T03:02:19.000Z","updated":"2019-05-05T03:23:42.770Z","comments":true,"path":"2019/05/05/Ubuntu16.04下误删chromium书签恢复/","link":"","permalink":"https://AIpynux.github.io/2019/05/05/Ubuntu16.04下误删chromium书签恢复/","excerpt":"","text":"如果误删了chromium书签或书签文件夹，不要慌张，先直接关掉chromium。找到~/.config/chromium/Default目录下的Bookmarks和Bookmarks.bak文件，Bookmarks是当前书签文件，Bookmarks.bak是书签修改前自动备份的书签文件，所以只要误删后没有再次增删书签，我们删掉Bookmarks文件后，再将Bookmarks.bak文件重命名为Bookmarks文件，再重启chromium即可恢复书签。","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"Chromium,Ubuntu","slug":"Chromium-Ubuntu","permalink":"https://AIpynux.github.io/tags/Chromium-Ubuntu/"}]},{"title":"Ubuntu16.04关机太慢","slug":"Ubuntu16.04关机太慢","date":"2019-05-02T05:44:25.000Z","updated":"2019-05-02T06:38:42.112Z","comments":true,"path":"2019/05/02/Ubuntu16.04关机太慢/","link":"","permalink":"https://AIpynux.github.io/2019/05/02/Ubuntu16.04关机太慢/","excerpt":"","text":"修改关机时关闭服务的响应时间：1sudo vim /etc/systemd/system.conf 将文件中的DefaultTimeoutStopSec的值改为10s。 注意：关机前务必手动关闭已打开的程序，防止因为关闭服务时间过短而导致的文件丢失。","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://AIpynux.github.io/tags/Ubuntu/"}]},{"title":"基于SSM实现高并发秒杀API课程笔记","slug":"基于SSM实现高并发秒杀API课程笔记","date":"2019-05-02T03:37:31.000Z","updated":"2019-05-17T09:48:59.957Z","comments":true,"path":"2019/05/02/基于SSM实现高并发秒杀API课程笔记/","link":"","permalink":"https://AIpynux.github.io/2019/05/02/基于SSM实现高并发秒杀API课程笔记/","excerpt":"","text":"课程概述为什么使用SSM框架 易用且轻便 互联网公司常用 低业务代码侵入性 成熟的社区和用户群 为什么选用秒杀类系统进行讲解 秒杀类业务场景具有典型的”事务”特性 秒杀和红包类需求越来越常见 面试常问问题 事务的四大特性原子性(atomicity):一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作，这就是事务的原子性。 一致性(consistency):数据库总是从一个一致性的状态转换到另一个一致性的状态。在前面的例子中，一致性确保了，即使在执行第三、四条语句之间时系统崩溃，前面执行的一、二语句也不会生效。因为事务最终没有提交，所以事务中所做的修改都不会保存到数据库中。 隔离性(isolation):通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。当执行第三条语句、第四条语句还未开始时，此时有另外一个程序开始运行，则看不到第三条语句做出的改变。 持久性(durability):一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。持久性是个有点模糊的概念，因为实际上持久性也分很多不同的级别。有些持久性策略能够提供非常强的安全保障，而有些则未必。而且不可能有能做到100%的持久性保证策略。 相关技术要求MySQL SQL技巧 事务和行级锁 表设计(手写代码) MyBatis DAO层设计与开发 MyBatis合理使用 MyBatis与Spring整合 Spring Spring IOC整合Service 声明式事务运用 Spring MVC 框架运作流程 Restful接口设计和使用 Controller开发技巧 前端 交互设计 Bootstrap JQuery 高并发 高并发点和高并发分析 优化思路并实现 学习成果 SSM整合与使用 秒杀类系统需求理解与实现 常用场景高并发解决方案 SSM整合与使用基于Maven创建项目要点 项目从零开始创建 从官网获取相关配置 使用Maven创建项目 官网地址Logback配置：https://logback.qos.ch/manual/configuration.htmlSpring配置：https://docs.spring.io/spring/docs/MyBatis配置：http://www.mybatis.org/mybatis-3/zh/index.html 使用Maven命令创建Web骨架项目1mvn archetype:generate -DgroupId=org.seckill -DartifactId=seckill -DarchetypeArtifactId=maven-archetype-webapp 注意：archetype:create这个goal已在新版本Maven中弃用。 pom.xml是Maven项目的配置文件。 使用Maven创建的项目中的web.xml中Servlet版本可能过低，我们通过复制Servlet容器服务器如Tomcat的实例目录中的WEB-INF中的web.xml高版本的文件头进行替换。 补全项目目录(src-main-java、src-test、src-test-java和src-test-resources)。 改变pom.xml下默认junit依赖版本为4.11，因为junit3使用编程方式测试，而junit4使用注解方式进行测试。 补全项目依赖。 日志(slf4j,log4j,logback,common-logging)：slf4j是规范/接口;log4j,logback,common-logging是日志实现;\\常用组合：slf4j + logback。 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 实现slf4j接口并整合进来，编程时只需使用slf4j(使用其他日志实现时也会有个类似这样进行整合的依赖，所以编程时都能统一使用slf4j) --&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt; 数据库(数据库驱动和数据库连接池) 1234567891011&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.35&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt;&lt;/dependency&gt; DAO框架(MyBatis本身依赖和MyBatis与Spring整合依赖) 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- MyBatis自身实现的与Spring之间的整合依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; Servlet Web相关依赖(JSP相关标签库,jackson和Servlet依赖) 12345678910111213141516171819202122&lt;dependency&gt; &lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jackson依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Servlet依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt; Spring依赖(4大方面) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;!--1) Spring核心依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 包含SpringIOC依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Spring扩展(如包扫描)依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--2) Spring DAO层依赖 --&gt;&lt;!-- 需要Spring-jdbc提供的事务管理器 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 需要Spring-tx提供的声明式事务 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 3) Spring Web相关依赖(容器需要加载Spring IOC和Spring AOP来启动Spring的工厂) --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;nversion&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 4) Spring test相关依赖,方便我们使用junit做单元测试和集成测试 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 业务分析与DAO层秒杀业务分析秒杀业务的核心：对库存的处理 用户针对库存业务分析 用户购买行为 关于数据落地不加事务会造成超卖和少卖的情况NoSQL相比MySQL，虽然分化注重了高可用、高并发和分布式的特性，但是事务支持性差。 MySQL实现秒杀系统难点多个用户参与活动时产生竞争，竞争反应到MySQL背后的技术是事务和行级锁。这一事务由Start Transaction、Upate 库存数量、Insert 购买明细和Commit组成。主要的行级锁位于Update 库存数量时。而系统的难点就是如何高效的去处理这样的竞争。 系统要实现的秒杀功能 秒杀相关查询 秒杀接口暴露 执行秒杀 代码开发阶段 DAO设计编码(数据库表设计、DAO接口和MyBatis实现DAO) Service设计编码(Service接口、Spring管理Service和通过声明式事务简化事务控制) Web设计编码(Restful接口和前端交互) 数据库表设计 手写DDL让同行间的交流更加方便。 MySQL提供可选的引擎有很多，但支持事务的只有InnoDB。 MySQL 5.7 及以后的版本中explicit_defaults_for_timestamp的值默认都是OFF。 DAO层接口设计和编码已设计的数据表对应Java中的实体。给实体和DAO接口创建好包。 实体设计注意变通，在SuccessKilled实体中需要拿到Seckill实体，其实这个意味着多对一的复合属性。 DAO接口设计 DAO层关注着数据库操作。 接口命名规范：实体名+DAO。 接口设计其实对应着数据的增删改查，并且接口内方法的设计也有相应规范。 具体接口的实现可以用JDBC或Hibernate或MyBatis。 基于MyBatis实现DAO理论 MyBatis完成的是实体对象与数据库间的映射工作(OR Mapping)。 MyBatis需要我们提供参数和SQL(Hibernate没有)，之后它返回给我们结果。 SQL可以写在xml文件中或着注解当中，写在xml文件中比较灵活轻便。 DAO接口可以通过MyBatis中的Mapper机制自动实现(推荐)，也可以通过API编程方式自己实现接口。 基于MyBatis实现DAO编程 在src-resources目录下创建全局的MyBatis配置文件mybatis-config.xml。 在src-resources目录下创建放置MyBatis映射文件的mapper目录。 从MyBatis官网获取配置头文件。 设置useGeneratedKeys的值为true，让MyBatis可以使用JDBC的getGeneratedKeys获取数据库自增主键值。 设置可以使用列别名替换列名使用(useColumnLabel默认为true)，这样MyBatis自动帮我们实现实体属性与表属性间的转换(select name as title from table)。 设置开启(mapUnderscoreToCamelCase)驼峰命名转换(Table(create_time) -&gt; Entity(createTime))。 mapper目录中的xml文件能为DAO接口方法提供SQL语句配置。 xml文件中有相应标签(insert、delete、update和select)对应方法要实现的增删改查。 xml文件中不允许有&lt;=这样的语法，我们在写SQL语句时可以用&lt;![CDATA[&lt;=]]&gt;来告诉xml这里的&lt;=不是xml的语法，这样就能用了。 resultType类型如果是自创的实体，在表示的时候可以先不写包名只写类名，因为后面的配置中可以给出一个包名的环境变量。 如果方法中的返回类型是List这样的泛型，在写resultType时直接写List里面包含的对象类型，如这里的项目中是List包含的是自创的实体类型Seckill。 SQL语句中可以用limit来限制查询结果的行数。 insert时如果主键重复会报错，我们可以忽略主键重复(ignore)报错而返回0，让我们更好的去处理这个逻辑。 用inner join … on …链接可以将一个实体属性带入另一个实体。 这样的链接语句其实也是体现MyBatis技巧的一个载体(它能告诉MyBatis把结果映射到两个不同实体)。 表的别名设置时可以省略as关键字，表的别名可以与驼峰命名转换机制组合使用。 MyBatis可以通过列别名与当前实体中另一实体类对象属性组合的方式来映射到另一个实体。 上述的列别名组合实际上可以理解为一个el表达式。 MyBatis相对其他ORM框架的优势在于可以让我们自由控制SQL，完美地发挥我们工程师的SQL技巧。 MyBatis整合Spring理论整合目标 更少的编码体现：只写接口，不写实现类(MyBatis为我们实现)。理由：接口就能告诉我们很多事情：方法的结果集、行为和参数。 更少的配置体现：自动实现DAO实现类并注入到Spring容器。 足够的灵活体现：整合之后我们依然可以灵活的自己定制SQL。 整合步骤 别名的设置：MyBatis帮我们实现了package scan的功能，使得我们不需写包名就能表示一个类。 MyBatis还实现了自动扫描配置文件的功能，所以不需要我们额外再告诉MyBatis项目中的mapper目录下放置的是DAO对应的SQL配置文件。 一般情况DAO实现类的配置也要写到xml文件中以告诉Spring容器，而这里MyBatis为我们自动实现DAO接口且MyBatis与Spring整合后可以自动将这个告知的步骤也实现。 MyBatis整合Spring编码 创建main-resources-spring目录，用来存放Spring相关配置。 新建spring-dao.xml存放DAO相关配置，从官网下载PDF格式官方文档，找到容器相关章节，复制Spring的xml配置文件头。 (1)配置数据库相关参数，写在properties文件(jdbc.properties)下。Spring配置支持classpath:前缀(指的是main-java和main-resources目录)和${url}(用来获取properties文件中的属性)。 jdbc.properties文件的配置代码:1234driver = com.mysql.jdbc.Driver url = jdbc:mysql://127.0.0.1:3306/seckill?useUnicode=true&amp;characterEncoding=utf8 username = root password = hgneer 在spring-dao.xml文件中配置数据库连接池(bean id = “dataSource”)，配置连接池属性(driverClass、jdbcUrl、user和password)和连接池私有属性：maxPoolsize(30)、minPoolSize(10)、autoCommitOnClose(把连接放到池中前需要一些清理工作，设置为false，使得当关闭连接时不要commit)、checkoutTimeout(获取连接超时时间，一般设置为1000，否则默认是0就会无限等待)和acquireRetryAttempts(获取连接失败重试次数，一般设置为2)。 配置MyBatis中最重要的一个API(bean id = “sqlSessionFatory”)：SqlSessionFactory对象用来创建会话工厂。 有以下要点： 输入数据库连接池。 配置MyBatis全局配置文件为mybatis-config.xml。 配置扫描entity包(如果要省略多个包可以用分号隔开即可)，使用别名。 配置自动扫描sql配置文件：mapper需要的xml文件。 配置扫描DAO接口包，使得动态实现DAO接口，注入到Spring容器中。 有以下要点(class = “org.mybatis.spring.mapper.MapperScannerConfigurer”)： 注入sqlSessionFactory，注意使用sqlSessionFactoryBeanName，这样只有当我们使用时才加载，防止初始化滞后而导致的错误。 给出需要扫描的DAO接口包位置,以便于后面的MyBatis动态实现和自动注入。 总结: MyBatis与Spring整合本质上是一些配置。 约定大于配置的启示，在特定包下新增特定类型文件，框架帮助自动识别，不需要额外配置。 DAO层单元测试编码与问题排查 单元测试代码放在test-java目录。 因为DAO的实现类是MyBatis自动实现和注入到Spring容器的，所以在测试之前需要配置Spring与Junit整合。 让Junit启动时加载SpringIOC容器，使用spring-runner提供了@RunWith(SpringJUnit4ClassRunner.class)。 告诉JUnit Spring DAO配置文件，使用@ContextConfiguration({“classpath:”})。 注入DAO实现类依赖，使用@Resource(依赖注入注解)private SeckillDao seckillDao; 因为Java不会保存形参的记录，只以org0，org1这种形式表示，当方法只有一个参数时没事，但在DAO接口方法有多个参数时注意用MyBatis提供的@Param(“offset”)来标识，否则在SQL语句执行时找不到对应的参数。 阶段性测试，现在是测试数据绑定间是否存在问题，等Service写完再测逻辑层面的问题。 控制台信息可以复制到编辑版面进行可视化，更好地定位错误。 Service层完成DAO层后的思考 DAO层没写一行逻辑代码，让代码与SQL分离，方便Review。 DAO层工作演变为：接口设计+SQL编写。 DAO层拼接等逻辑在Service层完成。 Service层设计和开发Service接口设计 创建Service层所需要的包:service(存放Service接口和实现类)、exception(存放异常)和dto(存放表示数据的一些类型，关注Web层和Service层的数据传递)。 站在”使用者”角度去设计接口，设计接口时不要去关注实现。从三个方面来站在”使用者”角度设计接口：方法定义粒度要明确、参数要简练直接和返回类型要友好(有时返回的类型不适合用一个entity，就需要额外定义的dto类)(return 类型/异常)。 比如要有一个控制暴露秒杀地址的接口方法设计，这个方法在设计时根据需求要设计一个dto类作为返回类型。 dto设计使用md5作为加密措施。做不同的Constructor是为了方便我们进行不同初始化。 自己在exception目录下设计异常类，要分清楚运行期异常(运行期异常不用try-catch)和编译期异常，但是Spring的声明式事务只接收运行期异常回滚策略(所以我们创建的异常类继承RuntimeException，并生成message的两个构造方法)。 另外，一般情况，使用Spring，我们可以做一个通用的异常，然后让其它异常继承这个异常，当然，这个异常是继承自RuntimeException。 Service接口实现 创建service-impl作为实现类的包，实现类的命名是接口名+Impl。 在具体实现接口时，需要用到DAO类的配合，所以在实现类中声明需要的DAO类对象，但不用初始化，因为DAO类是MyBatis自动实现和注入Spring容器的。 另外，实现类编写时还需要引入日志对象(这里用的slf4j)。(private Logger logger = LoggerFactory.getLogger(this.getClass()))。 系统的当前时间new一下就是：Date nowTime = new Date()，且nowTime.getTime()是表示毫秒个数的一个long类型的数字。 md5如何生成：加入一个混淆过程将用户特定字符串进行转换，所以先创建一个md5盐值字符串，用于混淆制作md5，然后创建一个方法，在这个方法里面调用Spring为我们提供的专门生成md5的工具类方法(DigestUtils.md5DigestAsHex(base.getBytes()))。 如果有重用的点，那抽象出一个方法出来就没毛病。 异常类的message有什么方法可以呈现到前端页面？ 在实现执行方法时try-catch可能出现的编译期异常也都可以throw到我们之前创造的通用业务异常(运行期异常)，这样我们在出现未知异常时，Spring由于针对运行期异常，那么它就会为我们做rollback(很关键)，当然，这个catch要放最后，应该先catch子类异常。 用枚举来存储常量数据字典。 对象在使用默认的json进行转换时对枚举转换会出问题。 使用Spring托管Service依赖理论Spring IOC(依赖注入)理解 Spring IOC提供一个对象工厂帮我们创建Service的实现并完成Service当中的依赖管理，最终给我们一个一致的访问接口。也就使得我们不用管创建过程和依赖管理，直接使用一致接口获取实例。 业务对象依赖图 为什么用IOC? 对象创建统一托管。 规范的生命周期管理(让我们在特定生命周期增删逻辑更方便)。 灵活的依赖注入(可以编程，可以注解，可以第三方)。 一致地获取对象实例(这些对象实例还都是默认单例的)。 Spring IOC注入方式和场景 Java配置类：需要代码控制对象创建逻辑的场景，如自定义修改类库(不常用)。 注解：项目自身开发使用的类，可直接在代码中使用注解，如@Service、@Controller等。 xml:Bean实现类来自第三方类库，如DataSource；需要命名的空间配置如context、aop、mvc等。 本项目IOC使用 XML配置 package-scan(DAO) Annotation注解(Service) 使用Spring托管Service依赖配置 在resources-spring目录下创建spring-service.xml文件，来配置Service，目的让Spring扫描service包下所有使用注解的类型并注入到容器(&lt;context:component-scan base-package=”org.seckill.service”/&gt;)。 另外，开始对自己开发的Service来完成基于注解的配置。 Spring提供的几种注解：@Component(组件统称)、@Service、@Dao和@Controller。 MyBatis自动实现了DAO类对象在Service类使用时，需要使用@Autowired注解(或者@Inject、@Resource)来注入Service依赖。 Spring声明式事务 什么是声明式事务？正常一个事务过程包括：开启事务-修改SQL1-修改SQL2-修改SQL3-等等-提交/回滚事务。那使用声明式事务后，事务的开启和结尾阶段都交由第三方框架完成，我们不需要关心，只关心SQL操作，解脱了我们的事务操作。 Spring声明式事务的使用方式： ProxyFactoryBean + XML : 早期使用方式(2.0)。 tx:advice + aop命名空间 ： 一次配置永久生效。 注解@Transactional : 注解控制(推荐，这样会在方法中加入注解，便于团队间的交流。)。 事务方法嵌套 这是声明式事务独有的概念，和MySQL无关 Spring默认的传播行为(当有多个方法调用时是创建一个新事务还是加入到已有的事务)是propagation_required(它是如果事务有，加入到原有事务当中) 什么时候回滚事务? 当方法抛出运行期异常(RuntimeException)，很重要 所以要小心谨慎的try-catch 配置并使用Spring声明式事务在spring-service.xml文件中配置事务声明管理器：MyBatis采用的是JDBC的事务管理器，所以引入spring默认的transactionManager。 配置注入数据库连接池(这里有个小问题，在dataSource命名空间下找不到ref=”dataSource”,这是因为我们配置的dataSource在spring-dao.xml文件中，这里找不到没关系，到时候运行时两个xml文件都给到Spring，它会自动帮我们找到)。 配置基于注解的声明式事务(tx:annotation-driven transaction-manager=”transactionManager”)，这样就使得可以默认使用注解管理事务行为。 使用注解控制事务方法的优点： 开发团队达成一致约定，养成明确标注事务方法的编程风格。 保证事务方法的执行时间尽可能短，将网络操作如RPC/HTTP请求等耗时操作剥离到事务方法外部。 不是所有的方法都需要事务，如果只有一条修改操作或一般的只读操作(因为只读操作不会对数据库进行修改，不会用到回滚。)是不需要事务控制的。 集成测试Service逻辑 主要针对业务实现类。 首先还是需要配置Spring-Junit依赖：@Runwith(SpringJUnit4ClassRunner.class)@ContextConfiguration({“classpath:spring/spring-dao.xml”,“classpath:spring/spring-service.xml”}) 用Spring注解@Autowired方式注入我们的测试对象实例。 配置日志管理logback:在resources目录下创建logback.xml文件，将官网的配置头文件(默认的直接打印到控制台)和xml头拷贝进去 logger.warn可用于警告。 测试代码要能覆盖完整逻辑且注意可重复执行。 Web层设计与实现内容概述 前端交互设计 Restful接口设计 Spring MVC Bootstrap + JQuery 前端交互流程设计标准：根据用户需求设计前端交互流程涉及的人员：产品、前端和后端 前端页面流程 详情页面流程 学习Restful接口设计什么是Restful 兴起于Rails 一种优雅的URI表述方式 关于状态转移(动词)和资源的状态(名词表示) Restful规范 GET -&gt; 查询操作 POST -&gt; 添加/修改操作(非幂等) PUT -&gt; 修改操作(幂等[一个操作执行多次与一次的结果一样且不会对系统造成崩坏性的影响]) DELETE -&gt; 删除操作 Restful的URL设计/模块/资源/{标示}/集合1/…如：/user/{uid}/frends -&gt; 好友列表&nbsp;&nbsp;&nbsp;&nbsp;/user/{uid}/followers -&gt; 关注者列表 秒杀API的URL设计 GET /seckill/list -&gt; 秒杀列表 GET /seckill/{id}/detail -&gt; 详情页 GET /seckill/time/now -&gt; 系统时间 POST /seckill/{id}/exposer -&gt; 暴露秒杀 POST /seckill/{id}/{md5}/execution -&gt; 执行秒杀 总结使用Restful接口可以方便伙伴间的交流，养成良好的设计思路和风格。 Spring MVC整合Spring使用Spring MVC框架理论概述：我们始终围绕Handler开发页面View的格式可以是Json、JSP甚至PDF。 Spring MVC运行流程 DispatcherServlet : 中央控制器的Servlet，会拦截用户所有的请求。 DefaultAnnotationHandlerMapping : 用来映射URL，明确我们哪些URL对应哪些Handler。 DefaultAnnotationHandlerAdapter : 用来做一个Handler适配，衔接我们编写的Controller(如果用到Intercept拦截器，它也会将拦截器绑定在我们的流程当中)。 上述步骤产生的ModelAndView交付到DispatchServlet后，会根据我们应用的View格式匹配相应的ViewResolver，然后解析后将View与Model相结合返回给用户。在使用jsp我们可以设置返回一个字符串，这个字符串对应一个jsp页面，而使用json做view的话只要把图中jsp改成json即可。 HTTP请求地址映射原理 注解映射技巧@RequestMapping注解：(1) 支持标准的URL(2) Ant风格URL 如/user/*/creation(3) 带{xxx}占位符的URL 如/user/{userId} Spring MVC请求方法细节处理 请求参数绑定 请求方式限制(写的Handler方法只允许GET或POST或PUT等提交，如何限制) 重定向和请求转发 数据模型赋值(将什么样的数据传递给jsp或json) 一个可以展现上诉各个细节处理的例子: 返回json数据 cookie访问 整合配置Spring MVC框架在WEB-INF目录下的web.xml文件配置Spring MVC框架： 配置DispatchServlet(servlet-name和servlet-class)。 配置Spring MVC需要加载的配置文件：spring-dao.xml、spring-service.xml和spring-web.xml，且配置的加载顺序是：Mybatis-Spring-Spring MVC。 做Servlet的Mapping，直接用/表示默认匹配所有请求，让所有请求都转到DispatchServlet当中。 新建resources-spring-spring-web.xml文件进行配置： 开启Spring MVC注解模式(mvc:annotation-driven)，它实质上是一个简化配置，完成了以下功能：(1) 自动注册DefaultAnnotationHandlerMapping和DefaultMethodHandlerAdapter。(2) 提供一系列功能：数据绑定、数字和日期的format(@NumberFormat、@DateTimeFormat)、xml和json的读写支持。 因为配置的servlet-mapping的映射路径是”/“，所以在这里我们需要有一个静态资源默认servlet配置(mvc:default-servlet-handler)，它也有两个作用：(1) 允许使用”/“做整体映射。(2) 加入对静态资源的处理：js，gif，png等。 配置jsp显示对应的ViewResolver(InterResourceViewResolver、viewClass、prefix和suffix)。 还可以配置json，但是第一步配置其实已经默认开启了。 配置扫描web相关的包(和之前DAO层与Service层类似要进行的配置)。 需要拦截器就在额外进行相应配置(从官网获取)。 实现秒杀相关的Restful接口 新建java-web目录用于存放Controller类，用这些Controller类来实现Restful接口。 在Controller类上面加上几个注解：@Controller和@RequestMapping(“/seckill”)(用来作为URL映射地址的/模块)。 具体方法实现层，list.jsp + model = ModelAndView，Model对象用来存放(使用model.Attribute()方法)渲染所需的数据。\\方法的返回值结合之前对VieResolver的配置可以直接返回一个字符串来对应一个jsp页面。另外，方法上层需要使用RequestMapping\\进行二级的URL映射和限制对应HTTP请求方式。 当然，Controller方法层次上的实现要对Service层进行调用，所以也需使用注解的方式(@Autowired和@Resources等)将Service对象依赖注入到Controller类中。 此外，类里面也需配置日志对象对各种信息进行管理。 RequestMapping中使用占位符时需要在方法的参数设置上加上@PathVariable(“seckillId”)这种类似代码。 用redirect:/seckill/list或forward:/seckill/list可以用来重定向和请求转发。 Contorller控制层也就是接收某些参数后，结合我们设计好的dto类型为我们做跳转控制。 AJax的Restful方法接口实现时的返回类型一般设置为json类型，然后在方法前方除了需要进行\\@RequestMapping注解,还需要加上@ResponseBody注解来告诉Spring MVC这个方法的返回类型\\算作一个json，此外，最好在@RequestMapping下额外加上参数produces = {“application/json;charset\\=UTF-8”}\\来告诉浏览器我们的contentType来防止json或者中文乱码问题，养成良好的习惯。 AJax所需要的json类型需要自己创建一个dto类来进行封装，这个类一般设置为泛型，使得所有的AJax请求返回类型都可以用此类设置。 方法的参数从Cookie中获取时需要加上@CookieValue(value = “killPhone”,required = false)的设置。\\另外，这里设置的required = false是说当cookie中获取不到killPhone变量时不要让Spring MVC\\来报错，而是赋予我们程序来处理这样一个逻辑的机会。 系统当前日期直接使用Date now = new Data()来new一个对象即可。 基于bootstrap开发页面结构 采用CSS直接埋点的方式为我们提供了很多方便的样式。 我们直接通过拷贝HTML模板方式使用bootstrap。 在WEB-INF目录下新建jsp目录用来存放jsp文件，jsp文件头用拷贝过来的HTML模板替换，之后修改。 使用的这个模板帮我们简单做了一些浏览器的适配，引入了JQuery库，但是模板上使用的bootstrap是一个压缩版本，我们找一个好的CDN版本进行替换，另外，CDN版本中的主题代码一般不使用。 需要注意使用CDN版本bootstrap后，我们在调试时需要全程联网。 jsp通用的头文件代码可以独立出来放到jsp-common目录下作为head.jsp，然后在具体jsp\\文件中用静态引入(&lt;%@include file = “common/head.jsp”%&gt;)的方式引入。(静态引入是直接\\将被引用文件中jsp代码插入引用文件中，只开一个Servlet；动态引入则是开多个Servlet，是\\将被引用jsp文件运行后的结果html代码合并到引用文件结果html代码中。) 使用bootstrap建议将所有显示内容放在几个div骨架下： 12345678&lt;div class = \"container\"&gt; &lt;div class = \"panel panel -default\"&gt; &lt;div class = \"panel-heading text-center\"&gt; &lt;/div&gt; &lt;div class = \"panel-body\"&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 具体的显示内容div放在panel-body下，至于需要使用的列表各种组件样式就查询bootstrap官网使用即可。table的创建：table-thead-tr-th做表头，table-tbody-tr-td做表行。表行里的内容一般用core标签来迭\\代从bean中获取(c:forEach var = “sk” items = “${list}”)。 若需要使用的jstl这样的标签库，引入代码也是可以独立成为一个tag.jsp文件用于静态引入。需要的两个标签是：core和fmt。 用fmt格式化时间显示举例：&lt;fmt:formatDate value = “${sk.startTime}” pattern = “yyyy-MM-dd HH:mm:ss”&gt;。 可以使用bootstrap做一个按钮式的超链接样式。 交互逻辑编程cookie登录交互 bootstrap的Modal插件可以为我们做一个弹出层，bootstrap的modal的CSS规范是：\\modal-content + modal-body + modal-footer。 埋点id=”killPhoneModal”可以方便我们使用id来查询到对应的整个div组件。 input可以给用户填写信息，span标签则可用于显示出错信息。 JQuery的Cookie操作插件和countDown插件可以使用bootstrap为我们提供好的一个CDN\\(http://www.bootcdn.cn)来直接获取。 使用CDN是Web项目一个很好的加速点。 新建webapp-resources-script目录，在此目录下编写js文件完成交互逻辑编程。 写好的js文件可在jsp文件中用&lt;script src = “/resources/script/seckill.js” type = “text/javascript”&gt;&lt;/script&gt;来引入，注意此处有个小坑，&lt;/script&gt;不能用&lt;/&gt;来替代，否则javascript代码会不能执行。 注意写javascript时要做到模块化，java的模块化可以通过分包来实现，javascript中没\\有package的概念，但是我们可以用json对象来封装多个对象来使得之后调用时产生一个分包\\模拟效果，让我们规范我们的程序编写风格。另外，正式写代码前一定要先规划好我们的交互流程。 一开始的初始化放在init中，在jsp文件中使用&lt;script type = “text/javascript”&gt;\\$(function())可以调用javascript方法并且使用EL表达式传入bean中的参数到javascript对象方法。 由于已经使用cookie插件，在javascript文件中我们可以直接使用$.cookie(‘killPhone’)的方式获取cookie数据。 javascript中访问jsp设置的参数方式：var startTime = parames[‘startTime’]。 验证操作最好放在javascript代码最上层，利于复用。 在javascript中可以通过#号用选择器的方式选中jsp中的一段组件，如$(‘#killPhoneModal’)。 Modal类型的控制输出(点击事件、键盘事件等)可以调用它自身的一个方法来实现。 控制显示出弹出层后，我们应该为弹出层的组件做数据绑定。 cookie为什么不给全路径，一般只绑到/模块？ 往页面插更新内容时最好先隐藏一下再给个限制事件来显示出来，让界面显示对用户更加\\友好，防止他们看到中间等待页面。$(‘killPhoneMessage’).hide().html(‘手机号错误！‘).show(300); 计时交互设计 之前的时间对象实质上是放在json里面，我们用ajax的get操作可以拿到。 需要注意的是我们不希望js代码中直接出现与我们后端交互拿数据的代码，为了缓解\\这个问题，我们应该将想要请求数据的URL封装到js中json的URL对象里(做成一个function)。 javascript中也可以用console输出错误信息方便我们进行调试。 将计时模块抽取到一个function： countdown : function (seckillId,nowTime,startTime,endTime)。 计时加一秒，防止用户时间可能出现的偏差。 倒计时完成时需要有一个回调事件的操作(使用on)。 秒杀交互设计 绑定链接时最好用one而非click，因为click会一直绑定，one则只绑定一次点击事件。 所有节点显示操作之前最好都先隐藏一下，之后用逻辑来控制。 代码一点一点的重构，不要妄想一步登天。 Web层总结前端交互设计过程编码前选择先想清楚前端的交互过程。 Restful接口设计URL设计遵循Restful规范，在Controller中具体实现Restful接口。 Spring MVC使用技巧 Spring MVC配置和运行流程 DTO传递数据 注解映射驱动BootStrap和JavaScript使用 BootStrap样式 JavaScript模块化 JQuery和Plugin使用 高并发优化 高并发发生在哪里？首先可以分析一下业务流程：红色部分可能需要高并发，绿色部分则无关紧要。 为什么要单独获取系统时间？为了给我们的高并发优化做铺垫？因为这里考虑到一个场景：用户在秒杀未开始时肯定会频繁刷新页面，而我们为了提高系统的并发\\性，一般会把我们的页面静态化并且将css，js等静态资源放到CDN服务器上，也就是说要访问detail\\这样的页面，是不需要访问我们的系统，而是直接访问CDN服务器，那这个时候也就拿不到我们的系\\统时间所以我们要单独做一个请求来获取当前系统服务器的系统时间。 CDN的理解 CDN(内容分发网络)是加速用户获取数据的系统。 部署在离用户最近的网络节点上。 命中CDN不需要访问后端服务器。 CDN互联网公司一般会自己搭建或租用。 获取系统时间不用优化因为Java访问一次内存大约10ns，而访问系统时间本质上就是new了一个日期对象然后把这个对象返\\回给用户，那么这样一个操作如果不考虑GC的影响，一秒钟就可以做一亿次，所以不用优化。 秒杀地址接口分析 无法使用CDN缓存，因为CDN缓存的都是不变的数据，这个地址是在变的。 适合放在服务器端缓存：redis等，后端的缓存是可以由我们的业务逻辑来控制。 一致性维护成本低，可以在redis改，也可以在mysql改，也可以等超时后再改。 秒杀地址接口优化 秒杀操作的优化分析 无法使用CDN缓存。 后端缓存困难：库存问题，无法进行数据库的事务处理。 一行数据竞争：热点商品。 其他方案分析这些分布式组件组合在一起，并发量接受能力很强。但是痛点就在于成本：为什么不用MySQL解决？认为MySQL低效，然而一条update压力测试可以抗住约4w的QPS，也就说同一个产品一秒钟可以卖4w次。\\那是什么使得MySQL低效了？可以先看下Java控制事务行为的分析：延迟分析：本地机房的一个网络延迟就在0.5ms-2ms间了，如果加上JVM-GC操作时间，整个的QPS最大就在20左右了。异地机房(Tomcat和MySQL分开)时的QPS就更低了。瓶颈分析：Java客户端执行update放到服务器就有网络延迟，此外在java服务端与MySQL进行事务操作时又会有GC的操作。那把网络延迟和Java与MySQL通信的GC等等待时间加到整个事务时间内，这个时间就长了。优化分析： 如何判断一个Update更新库存成功？ Update自身没报错 客户端确认Update影响记录数那得到优化思路：把客户端逻辑放到MySQL服务端，避免网络延迟和GC影响。 如何放到MySQL服务端？ 定制SQL方案：update/ + [auto_commit] /，需要修改MySQL源码。 使用存储过程：让整个事务在MySQL端完成。(存储过程本身设计出来就是想让一组SQL组成\\一个事务，然后在服务端完成，避免用客户端去完成事务造成的一个性能的干扰，而一般Spring\\声明式事务和手动控制事务都是客户端控制事务，这样的控制在行级锁不多的时候完全OK，但是秒\\杀类的同一行竞争太激烈，这个时候就需要存储过程来发挥作用。) 优化总结 前端控制：暴露接口，按钮防重复。 动静态数据分离：CDN缓存，后端缓存。 事务竞争优化：减少事务行级锁持有时间。 redis后端缓存优化编码有逻辑变化控制且频繁需要访问数据库的一些资源可以交由redis进行后端缓存。我们现在的重点是用Java去访问我们本地已经搭建好的Redis来做缓存。 打开pom.xml文件，引入Java访问redis的客户端(我们用jedis)，可以从官网查看各种语言\\推荐使用的对应客户端。 在pom.xml文件中引入redis依赖。 我们来为暴露地址接口和秒杀执行接口做一个redis缓存。 常用的缓存编码设计如下：123456get from cache if null get db else put cachelogic 这样写逻辑上没问题，但是注意不要将这样的缓存控制直接写到业务逻辑当中(Service)。而是应该将这样的缓存控制写到DAO层，它才是放数据存储或缓存的一个层次。 新建dao-cache包，在这个包内创建RedisDao，对这个类我们就直接在里面实现Redis的缓存控制，\\至少要设置JedisPool、构造方法、getSeckill和putSeckill。 数据库和jedis这样的close记得要的final里面执行。 构造Redis键值对时，需要注意redis和jedis都没有实现内部序列化操作，所以我们在赋值\\时要注意序列化的一个操作。 一般从Redis是获取一个二进制byte数组，到Java里我们应该反\\序列化成为一个对象，即：get -&gt; byte[] -&gt; 反序列化(字节数组到对象) -&gt; Object(Seckill)。\\此时注意高并发里面有一个很容易忽视的问题就是序列化的问题。一般序列化我们只需在Seckill.java\\实现一个Serializable，默认使用JDK自己的序列化机制。但是考虑高并发时我们就应该在序列化上再多\\做文章。Github有一个工程名为JVM-Serialization做了各种序列化工具性能的比对。我们决定采用性能高\\的序列化工具自定义序列化操作。 我们选择使用protostuff序列化工具，首先要在pom.xml文件中加上protostuff-core和protostuff-runtime两个依赖，之后我们一句protostuff的标准进行反序列化(告诉schema和字节数组，用ProtostuffIOUtil)。 put要做的工作就是将对象转成字节数组。 另外，注意养成一个好习惯，写完一个DAO后要写一个单元测试进行测试。 测试Redis的DAO时我们就注意要先在spring-dao.xml文件中自己注入RedisDao，我们使用的是构造方法注入。 之后在Service注入写好的RedisDao，让拿暴露地址时先访问Redis，没有再访问MySQL。 另外，这里的一致性建立在超时的基础上维护。 并发优化简单优化可以从行级锁持有时间入手，秒杀事务执行的过程之前是update-insert-commit/rollback，\\而行级锁在update时就开启了，我们可以改变这个事务过程为insert-update-commit/rollback来降低行\\级锁持有时间，同时也让客户端与MySQL间的网络延迟和GC处理时间降低了一倍，达到优化的目的。 深度优化使用存储过程将事务MySQL放在MySQL端执行，进一步降低网络延迟的影响。\\要提高并发量，需要想尽办法降低行级锁到commit的持续时间。 在sql目录下新建seckill.sql文件，在里面写秒杀执行的存储过程。 在存储过程中默认和MySQL终端一样也是通过分号(;)来作为分行符，我们首先使用DELIMITER $$\\使得存储过程中用$$表示分行符。 定义存储过程(in 输入参数 out 输出参数 row_count() 返回上一条修改类型(insert、delete和update)sql\\的影响行数)： 1234567891011121314151617181920212223242526272829303132333435363738394041CREATE PRODUCER `seckill`.`execute_seckill` (in v_seckill_id bitint,in v_phone bigint, in v_kill_time timestamp,out r_result int) BEGIN DECLARE insert_count int DEFAULT 0; START TRANSACTION; -- success_killed是秒杀明细表 insert ignore into success_killed (seckill_id,user_phone,create_time) values (v_seckill_id,v_phone,v_kill_time); select row_count() into insert_count; -- row_count(): 0 执行生效但未修改数据； &gt;0 表示修改数据的行数；&lt;0 sql错误/未执行sql IF (insert_count = 0) THEN ROLLBACK; -- 之前的数据字典定义的返回结果：-2为内部错误 -1为重复秒杀 0为秒杀结束。 set r_result = -1; ELSEIF (insert_count &lt; 0) THEN ROLLBACK; set r_result = -2; ELSE update seckill set number = number - 1 where seckill_id = v_seckill_id and end_time &gt; v_kill_time and start_time &lt; v_kill_time and number &gt; 0; select row_count() into insert_count; IF (insert_count = 0) THEN ROLLBACK; set r_result = 0; -- 这个时候的insert_count &lt; 0可能是因为sql执行出错，也可能是因为等待行级锁超时了。 ELSEIF (insert_count &lt; 0) THEN ROLLBACK; set r_result = -2; ELSE COMMIT; set r_result = 1; END IF END IF; END;$$ 之后我们可以在MySQL终端通过以下代码调用存储过程： 12345678-- 把分行符转换回;DELIMITER ;-- 终端上赋值变量需要加@set @r_result = -3;-- 执行存储过程call execute_seckill(1003,13502178891,now(),@r_result);-- 获取结果select @r_result; 存储过程优化的是事务行级锁持有的时间，但不要过度依赖存储过程，存储过程在一般的\\互联网公司并不是重点，只是银行用的多，且在我们的秒杀系统并发优化的需要，只有遇到简\\单的逻辑而且需要高并发时才去应用存储过程。 我们的秒杀系统在用了存储过程之后经过测试一个秒杀单可以有6000的QPS。 那之前通过Spring声明式事务定义的秒杀操作要如何修改以应用存储过程？定义一个新的接口，这个接口是用存储过程来执行秒杀，这个接口的具体实现当然也就与Java客户端如何调用存储过程息息相关。 需要在seckillDao定义一个调用存储过程的逻辑，这个接口方法返回值类型可以设置为void，参数则需要传一个Map&lt;String,Object&gt; paramMap，接口实现当然还是在xml中配置让mybatis调用存储过程。 xml中调用的话注意使用statementType = “CALLABLE”，之后使用： 123456call execute_seckill( #&#123;seckillId,jdbcType=BIGINT,mode=IN&#125;, #&#123;phone,jdbcType=BIGINT,mode=IN&#125;, #&#123;killTime,jdbcType=TIMESTAMP,mode=IN&#125;, #&#123;result,jdbcType=INTEGER,mode=OUT&#125;) 之后在业务逻辑Service中调用Dao调用存储过程方法，当然在此之前需要我们自己创建一个\\Map作为该方法的参数：12345Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;(); map.put (\"seckillId\",seckillId); map.put(\"phone\",userPhone); map.put(\"killTime\",killTime); map.put(\"result\",null); 注意： 为什么我们需要设置一个Map作为该方法的参数，是因为我们结果result通过Map也\\能放到参数里面，这样当我们的存储过程执行完成之后，result被赋值。当然，这个过程也\\是可能发生异常的，注意try-catch。另外，要想通过MapUtils.getInteger(map,”result”,-2)\\来获取result，需要在pom.xml引入依赖commons-collections。Cotroller也是需要调用存储\\过程来执行秒杀。 记得阶段性测试。 系统部署架构系统可能用到哪些服务？ CDN(BootStrap,JQuery的依赖) WebServer：Nginx + Tomcat(HTTP服务器和应用服务器) Redis(服务器端的缓存，热点数据的快速存储) MySQL(事务) 系统部署架构图分库分表一般按照关键Id进行，把流量压力分散开来，而分库分表可以自己取模或者借用专门\\的框架来完成。 可能参与的角色： 开发 测试 DBA 运维 课程总结数据层技术回顾 数据库设计与实现 MyBatis理解和使用技巧 MyBatis整合Spring技巧 业务层技术回顾 业务接口设计和封装 SpringIOC配置技巧 Spring声明式事务使用和理解 WEB技术回顾 Restful接口运用 Spring MVC使用技巧 前端交互分析过程 BootStrap和JavaScript使用 并发优化 系统瓶颈点分析 事务，锁和网络延迟的理解 前端，CDN，缓存等理解和使用 集群化部署 参考链接 Java高并发秒杀API之业务分析与DAO层 Java高并发秒杀API之Service层 Java高并发秒杀API之Web层 Java高并发秒杀API之高并发优化","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://AIpynux.github.io/tags/SSM/"}]},{"title":"MySQL使用笔记","slug":"MySQL使用笔记","date":"2019-03-19T13:27:45.000Z","updated":"2019-05-17T09:50:39.475Z","comments":true,"path":"2019/03/19/MySQL使用笔记/","link":"","permalink":"https://AIpynux.github.io/2019/03/19/MySQL使用笔记/","excerpt":"","text":"下载地址https://downloads.mysql.com/archives/community/ 安装流程解压MySQL组件包1tar -xvf mysql-server_MVER-DVER_CPU.deb-bundle.tar 对于适用于64位Ubuntu16.04系统的MySQL 5.7.24版本组件包解压缩代码：1tar -xvf mysql-server_5.7.24-1ubuntu16.04_amd64.deb-bundle.tar 安装依赖库1sudo apt-get install libaio1 预设置MySQL1sudo dpkg-preconfigure mysql-community-server_*.deb 注意：也可以不预设置，那样可以通过Socket Authentication机制来充当密码。 安装MySQL各组件1sudo dpkg -i mysql-&#123;common,community-client,client,community-server,server&#125;_*.deb 如果用上述命令安装时因缺少依赖而警告，可以用以下命令修复：1sudo apt-get -f install 安装结果 所有配置文件放在/etc/mysql(如my.cnf) 所有二进制文件、库文件、头文件等放在/usr/bin和/usr/sbin(这两个目录都在PATH下，不用再额外为MySQL配置环境变量) 数据目录是/var/lib/mysql(进入需要root权限，一般用户下使用mysql需要修改该目录权限?) 启动MySQL Server在类Unix系统下启动mysqld server的推荐方式是用mysqld_safe(MySQL Server Startup Script)，mysqld_safe让server启动更加安全，它会在遇到错误时重新启动server以及将此刻运行时信息打到错误日志中。1mysqld_safe --user=mysql &amp; #需要root权限 测试MySQL Server查看MySQL Server信息1mysqladmin -u root -p version 关闭Server1mysqladmin -u root -p shutdown 重启Server1mysqld_safe --user=mysql &amp; 注意：如果使用deb格式文件安装MySQL组件后，第一次关闭Server再重启Server可能会遇到下列错误。 mysqld_safe Directory ‘/var/run/mysqld’ for UNIX socket file don’t exists. 错误提示告诉我们/var/run/mysqld目录不存在，但是我们如果仅是创建一个这样的目录也还是不行，它又会提示我们mysqsld.sock不存在。那实际上这个问题的出现是权限控制导致的，由于之前安装MySQL组件的命令中用了sudo，它使用这个权限完成安装后还用此权限自动开启了Server（开启Server的前提就是会在/var/run/mysqld目录下创建服务器启动所需的各种文件如mysqld.sock，mysqld.pid等），然而第一次关闭Server后系统会自动删除mysqld目录，所以我们再重新启动Server时mysql就找不到mysqld目录。那为什么自己创建一个mysqld目录后还是不行？因为/var/run/目录下的文件和文件夹在没有设置的情况下它们的所有者和组都是root，一般用户只有读和执行权限，mysql(用户和组)自己无法在这个文件夹中创建所需要的mysqld目录及目录下的mysqld.sock等文件，所以也还是启动不了。 所以解决此问题只需两步：1. 创建/var/run/mysqld目录 2. 将这个目录的所有者和所在组改为mysql。12mkdir -p /var/run/mysqldchown mysql:mysql /var/run/mysqld 测试从Server中攫取信息12345678910mysqlshow -u root -pEnter password: +--------------------+| Databases |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+ 1234567891011121314151617181920212223242526272829303132333435363738mysqlshow -u root -p mysqlEnter password: Database: mysql+---------------------------+| Tables |+---------------------------+| columns_priv || db || engine_cost || event || func || general_log || gtid_executed || help_category || help_keyword || help_relation || help_topic || innodb_index_stats || innodb_table_stats || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || server_cost || servers || slave_master_info || slave_relay_log_info || slave_worker_info || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+ 123456789mysql -u root -p -e \"SELECT User, Host, plugin FROM mysql.user\" mysqlEnter password: +---------------+-----------+-----------------------+| User | Host | plugin |+---------------+-----------+-----------------------+| root | localhost | mysql_native_password || mysql.session | localhost | mysql_native_password || mysql.sys | localhost | mysql_native_password |+---------------+-----------+-----------------------+ 如果能正常使用上述命令得到相应结果，恭喜你，说明MySQL组件安装成功。 管理MySQL用户账号可以使用mysql_secure_installation和MySQL WorkBench(一个MySQL图形界面客户端)。 其它注意事项 可以用mysqld_safe和mysql.server脚本等自动启动Server，用systemd和mysql.server脚本等关闭Server。 MySQL时区（Time Zone）有时也需要特别设置，否则在连接MySQL时可能会出错。 MySQL针对字符集和字符序有server级、database级、table级和column级的精确设置。 要避免在使用MySQL过程中出现乱码，必须对字符集和字符序理解到位，设置精准。 utf-8编码本身可能使用2\\3\\4个字节，但是MySQL的utf8编码只支持3字节，而表情数据需要4字节进行存储，所以不能在使用utf8字符集编码的表中存储，应该用utf8mb4。 SQL语句 DDL(Data Definition Languages)语句：常用的语句关键字有create、drop和alter等。 DML(Data Manipulation Languages)语句：常用的语句关键字有insert、delete、update和select等。 DCL(Data Control Languages)语句：常用语句关键字有grant和revoke等。","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://AIpynux.github.io/tags/MySQL/"}]},{"title":"MySQL学习路线","slug":"MySQL学习路线","date":"2019-03-19T08:38:23.000Z","updated":"2019-03-19T09:56:21.938Z","comments":true,"path":"2019/03/19/MySQL学习路线/","link":"","permalink":"https://AIpynux.github.io/2019/03/19/MySQL学习路线/","excerpt":"","text":"入门 推荐书籍 《21分钟MySQL基础入门》 《后端知识点总结——MYSQL》 《MySQL必知必会》 《MySQL Tutorial》 《高性能MySQL》 《MySQL技术内幕:InnoDB存储引擎》","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://AIpynux.github.io/tags/MySQL/"}]},{"title":"浦发总行信息科技岗面试","slug":"浦发总行信息科技岗面试","date":"2019-03-16T09:05:25.000Z","updated":"2019-03-16T10:57:46.210Z","comments":true,"path":"2019/03/16/浦发总行信息科技岗面试/","link":"","permalink":"https://AIpynux.github.io/2019/03/16/浦发总行信息科技岗面试/","excerpt":"","text":"面试内容总共一轮机试两轮面试,有空就安排,无固定先后顺序。 机试一些中等难度的程序设计题，现场编译环境有Java、C和C++。 一面综合面试分为结构化面试和技术面试。结构化面试：3个面试官对6个学生一组，每组2道题目，没人2分钟读题，3分钟演讲。技术面试：聊天/项目/优缺点/一页笔试题。要求：条理清晰，简洁大方，逻辑性强。 二面专业面试(3对1)：15分钟到20分钟，需要自我介绍且会问一些项目和算法的问题,职业规划、对浦发产品的了解等。要求：过硬的基础。 准备计划 机试多做一些《剑指Offer》上的题。 一面做一些结构化面试的题，为面试中可能遇到的不利情况提前做准备。准备一些固定思路、万能句式。 二面为什么想去浦发？项目的设计和实现细节，数据库增删查改等SQL命令、四大特性及应用场景和其它类型数据库（数据库比较重视），socket网络编程，Linux常用命令，数据结构与算法（排序算法，尤其是快排）,对投递岗位的理解，代码优化，高并发，Tomcat配置连接池如何配置最大连接数？ 注意事项穿的稍正式点，带上身份证。面试一般是在12:00左右，出行前注意考虑导航出错因素。","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://AIpynux.github.io/categories/工作笔记/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://AIpynux.github.io/tags/面试/"}]},{"title":"Java基础","slug":"Java基础","date":"2019-03-16T07:28:36.000Z","updated":"2019-03-16T09:01:56.672Z","comments":true,"path":"2019/03/16/Java基础/","link":"","permalink":"https://AIpynux.github.io/2019/03/16/Java基础/","excerpt":"","text":"JDK版本选择JDK7使用份额最大，JDK8正在取代JDK8，JDK11刚开始流行。主要使用JDK8，向后反思，向前展望。 Linux下环境变量设置在~/.bashrc文件下添加如下代码:1234export JAVA_HOME=/usr/jdk1.8.0_144export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JRE_HOME/libexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin","categories":[{"name":"编程笔记","slug":"编程笔记","permalink":"https://AIpynux.github.io/categories/编程笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://AIpynux.github.io/tags/Java/"}]},{"title":"廖雪峰Git教程笔记","slug":"廖雪峰Git教程笔记","date":"2019-02-24T12:47:12.000Z","updated":"2019-02-26T11:23:52.343Z","comments":true,"path":"2019/02/24/廖雪峰Git教程笔记/","link":"","permalink":"https://AIpynux.github.io/2019/02/24/廖雪峰Git教程笔记/","excerpt":"版本控制系统的作用 记录改动 协作编辑 Git的诞生Linus坚决反对CVS和SVN等集中式版本控制系统(因为速度慢且需要联网)–&gt;BitMover公司授权Linux社区商业软件BitKeeper免费使用权–&gt;Linus社区牛人试图破解BitKeeper的协议被BitMover公司发现–&gt;BitMover公司收回Linux社区BitKeeper免费使用权–&gt;Linus花两周时间用C语言写出了分布式版本控制系统Git","text":"版本控制系统的作用 记录改动 协作编辑 Git的诞生Linus坚决反对CVS和SVN等集中式版本控制系统(因为速度慢且需要联网)–&gt;BitMover公司授权Linux社区商业软件BitKeeper免费使用权–&gt;Linus社区牛人试图破解BitKeeper的协议被BitMover公司发现–&gt;BitMover公司收回Linux社区BitKeeper免费使用权–&gt;Linus花两周时间用C语言写出了分布式版本控制系统Git 集中式VS分布式分布式在本地就可保存历史痕迹，不用担心污染服务器，集中式提交就到服务器了，如果提交出错就比较麻烦。集中式版本控制系统的版本库放在中央服务器，分布式版本控制系统的版本库每个人的电脑上都有。集中式版本控制系统必须联网才能使用,分布式版本控制系统不必联网就能使用。分布式版本控制系统的安全性更高，分支管理特别优秀。集中式如果单点故障，大家甚至无法提交更无法开分支。 有趣的小知识以前软件GNU Interactive Tools也叫GIT，所以老版本Linux安装git需要使用命令sudo apt-get install git-core。当然，之后随着Git的名气越来越大，后来GNU Interactive Tools改名成了gnuit，git-core正式改名为git。 Unix的哲学之一“没有消息就是好消息” Git命令行的使用 在git add之前可以用git diff查看指定文件具体修改内容。 在进行版本回退之前可以使用git log查看历史commit记录，Git的commit_id是用计算得出的哈希值表示。 HEAD表示当前版本，HEAD^表示上一版本，HEAD^^表示上上一个版本，HEAD~100表示往上100个版本。 一般使用git reset –hard commit_id进行版本穿梭,此时commit_id尤其重要。 使用git reflog查看历史命令可以确保回退到过去版本后依然能查询到未来版本的commit_id。 工作区是Working Directory，版本库是Repository，暂存区是stage(或index)。 git add把要提交的修改放到暂存区，git commit则可以一次性将暂存区的所有修改提交到分支。 Git比其它版本控制系统优秀的其中一个原因是Git跟踪并管理的是修改，而非文件。 git diff HEAD – &lt;文件名&gt;可以查看指定文件在工作区和版本库中的区别。 使用git checkout – &lt;文件名&gt;将指定文件在工作区的修改撤回，使用git reset HEAD &lt;文件名&gt;将指定文件提交到暂存区的修改撤回，使用git reset –hard commit_id等版本回退操作将提交到版本库的修改撤回。 使用rm &lt;文件名&gt;删除文件后，工作区和版本库就不一致了，git status就会提示我们哪些文件被删除了，如果确认在版本库中也要删除该文件则再使用git rm &lt;文件名&gt;。 Git的两级提交机制是一大杀器？ 使用git remote add origin &lt;远程仓库URL&gt;将本地版本库与远程仓库关联。 git push -u origin master第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 因为各个分支用指针来管理，git的分支切换几乎可在瞬间完成。 git merge &lt;branch_name&gt;用于合并指定分支到当前分支。 合并分支时有时提示Fast-forward表示此次合并是”快进模式”，也就是把分支指针移动一下。 因为创建、合并和删除分支非常快，所以Git鼓励使用分支完成某个任务，合并后再删掉分支，这和直接在master分支上工作效果是一样的，但过程更安全。 合并对同一文件进行了不同修改的两个分支会出现冲突，此时用git status可以查看有哪些冲突的文件，之后打开对应文件会显示两个分支中该文件具体的不同。 解决冲突就是把Git合并失败的文件手动编辑为我们希望的内容，再提交。 git log –graph –pretty=oneline –abbrev-commit可以查看分支合并图。 不要使用Fast forward模式合并，这样的合并删除分支后会丢失分支信息且从合并图看不出曾经做过合并。 平时应该使用非”快速模式”合并分支，git merge –no-ff -m &lt;”注释信息”&gt; &lt;branch_name&gt;，注意使用这种方式在merge时生成一个新的commit，所以这样合并后就可以从历史信息中看出合并信息。 日常使用分支管理开发时要保证master分支是稳定只用来发布新版本，平时都不在上面干活而是在分支dev上干活之后合并。 创建Bug分支并修复Bug然后合并前，针对当前未完成提交的dev分支工作环境，使用git stash进行存储；创建Bug分支并修复Bug然后合并后，使用git stash list查看保存的工作环境，使用git stash pop(恢复后删除stash记录)或git stash apply &lt;指定stash&gt;(恢复后不删除stash记录)恢复工作环境。 开发一个新的feature，最好新建一个分支；如果要丢弃一个没有合并过的分支，使用git branch -D &lt;branch_name&gt;强行删除。 多人协作时一般需要向远程推送master和dev分支，Bug分支一般不需要远程推送。 从远程克隆仓库下来后默认只看到master分支，使用git branch -b dev origin/dev创建远程dev分支到本地进行开发。 git pull失败原因一般是没有指定本地分支dev分支与远程origin/dev分支的链接，此时使用git branch –set-upstream-to=origin/dev dev设置它们之间链接后再git pull即可。 push前如果git pull成功但是与当前库合并出现冲突时还是先手动处理冲突，之后再push。 rebase操作可以把本地未push的分叉提交历史整理成直线，使查看历史提交的变化更容易？ Git的标签实际也是指向某个commit的指针，跟分支很像但是分支可以移动，标签不行。 tag是让人容易记住有意义的名字，他与某个commit绑在一起，但更humanity。 使用git tag &lt;tag_name&gt;默认是打在最新提交的commit上，当然也能打到指定commit上，需要在后面添加相应的commit_id。 git show &lt;tag_name&gt;查看标签详情，另外由于标签总是和某个commit绑在一起，如果这个commit在两个分支都有，那两个分支都能看到该commit对应的标签。 命令git tag -a &lt;tag_name&gt; -m “blablabla…”可以指定标签信息。 命令git push origin &lt;tag_name&gt;可以推送一个本地标签；命令git push origin –tags可以推送全部未推送过的本地标签；命令git tag -d &lt;tag_name&gt;可以删除一个本地标签；命令git push origin :refs/tags/&lt;tag_name&gt;可以删除一个远程标签。 一个本地库关联多个远程库用git remote add多添加几个远程库URL即可。 可以使用git check-ignore检查.gitignore文件是否有哪条规则导致出错。","categories":[{"name":"编码笔记","slug":"编码笔记","permalink":"https://AIpynux.github.io/categories/编码笔记/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://AIpynux.github.io/tags/Git/"}]},{"title":"Git命令行使用笔记","slug":"Git命令行使用笔记","date":"2019-02-24T07:48:16.000Z","updated":"2019-02-26T11:24:31.350Z","comments":true,"path":"2019/02/24/Git命令行使用笔记/","link":"","permalink":"https://AIpynux.github.io/2019/02/24/Git命令行使用笔记/","excerpt":"ssh debug1: Trying private key: /home/hgneer/.ssh/id_dsa debug1: Trying private key: /home/hgneer/.ssh/id_ecdsa debug1: Trying private key: /home/hgneer/.ssh/id_ed25519 重新创建ssh秘钥文件时一定注意公钥一般会发生变化，此时记得给Github添加公钥，避免不必要的麻烦。 DSA用在Github的SSH不行。 git clone/git init 如果用Github托管的话，一般先去Github建立Repository然后在自己主机clone会方便些；用git init的话在git remote添加远程主机地址时就要去创建Github的Repository来充当地址。 虽然Git本身支持多种协议的远程主机地址，且通常使用git协议的地址速度最快，但是Github代码托管平台却只提供https和ssh协议的地址。","text":"ssh debug1: Trying private key: /home/hgneer/.ssh/id_dsa debug1: Trying private key: /home/hgneer/.ssh/id_ecdsa debug1: Trying private key: /home/hgneer/.ssh/id_ed25519 重新创建ssh秘钥文件时一定注意公钥一般会发生变化，此时记得给Github添加公钥，避免不必要的麻烦。 DSA用在Github的SSH不行。 git clone/git init 如果用Github托管的话，一般先去Github建立Repository然后在自己主机clone会方便些；用git init的话在git remote添加远程主机地址时就要去创建Github的Repository来充当地址。 虽然Git本身支持多种协议的远程主机地址，且通常使用git协议的地址速度最快，但是Github代码托管平台却只提供https和ssh协议的地址。 git remote 可以修改.git中的config文件来改变远程主机地址，但是注意Github上只有Public的Repository才能使用git协议的地址作为Git的远程主机地址。 自己添加远程主机的名字最好不要写成origin。 注意从远程主机clone下来后默认远程主机名是origin，可以用git clone -o &lt;想要的主机名&gt; 主机地址。 git fetch git fetch &lt;远程主机名&gt; &lt;远程分支名&gt; fetch得到的分支在Repository，之后通过checkout创建一个本地分支或者merge得到的分支或者rebase得到的分支 git merge是合并分支到当前分支，不管是本地分支还是远程分支 git rebase暂时不要用，留到后面理解，rebase是一种合并方式? git pull 取回远程分支的更新再与本地某分支合并 git pull &lt;远程主机名&gt; &lt;远程分支名&gt; : &lt;本地分支名&gt; 相当于git fetch + git merge -p可以使得在本地删除远程已删除的分支 git pull &lt;远程主机名&gt;表示与本分支的追踪分支进行更新及合并 git push 把本地的更新推送到远程并合并 git push &lt;远程主机名&gt; &lt;本地分支名&gt; : &lt;远程分支名&gt; (&lt;来源地&gt; : &lt;目的地&gt;) 省掉远程分支名则表示与追踪分支保持一致来推送 省掉本地分支名则表示推送一个空分支到远程分支，效果是删除远程分支 当本地分支与多个远程主机存在追踪关系可以用-u来选择默认远程主机 推送程度:simple(当前分支)、matching(所有对应远程分支的本地分支)、all（所有分支） 如果远程分支比本地分支新，git push 之前一般需要 git pull git push不会推送tags，除非加上–tags before git push,git fetch first and then git merge,or JUST git pull –rebase. git tag 标签命名与commit注释有关？ git log git log –name-status git log –author=hgneer git log –pretty=oneline git log –graph –oneline –decorate –all git branch git branch &lt;分支名&gt;是新建一个分支但不改变当前分支，git checkout -b &lt;分支名&gt;是新建一个分支并切换到该分支 git checkout - 切换到上一分支 git branch –set-upstream-to=&lt;远程分支名&gt;是为当前分支建立追踪分支 git commit git commit -v提交时显示所有diff信息在最下方 git commit –amend 可以修改制定commit对应的注释 撤销 git log 找到你想撤销的commit_id哈希值 git reset commit_id哈希值 完成Commit命令的撤销，但是不对代码修改进行撤销， git reset –keep commit_id哈希值 重置当前HEAD为指定commit，但保持暂存区和工作区不变 git reset –hard commit_id哈希值 完成撤销,同时将代码恢复到前一commit_id 对应的版本。","categories":[{"name":"编码笔记","slug":"编码笔记","permalink":"https://AIpynux.github.io/categories/编码笔记/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://AIpynux.github.io/tags/Git/"}]},{"title":"几个图片共享网址","slug":"几个图片共享网址","date":"2019-02-24T07:10:25.000Z","updated":"2019-02-24T07:43:25.015Z","comments":true,"path":"2019/02/24/几个图片共享网址/","link":"","permalink":"https://AIpynux.github.io/2019/02/24/几个图片共享网址/","excerpt":"","text":"汇图网 全景网 拍信网 给图网 视觉中国 红动中国 DreamsTime","categories":[{"name":"生活笔记","slug":"生活笔记","permalink":"https://AIpynux.github.io/categories/生活笔记/"}],"tags":[{"name":"资源","slug":"资源","permalink":"https://AIpynux.github.io/tags/资源/"}]},{"title":"配置Hexo主题之Melody","slug":"配置Hexo主题之Melody","date":"2019-02-03T09:22:10.000Z","updated":"2019-02-26T11:26:47.584Z","comments":true,"path":"2019/02/03/配置Hexo主题之Melody/","link":"","permalink":"https://AIpynux.github.io/2019/02/03/配置Hexo主题之Melody/","excerpt":"","text":"遇到问题使用Hexo的data file特性新建Melody主题的melody.yml配置文件后，将个人博客部署到本地，输入本地URL后，浏览器没有响应，提示代码如下: 123456789101112131415161718192021Unhandled rejection TypeError: /home/hgneer/Hexo/themes/melody/layout/includes/layout.pug:31 29| each url in theme.stylesheets 30| link(rel=&apos;stylesheet&apos;, href=url_for(url) + &apos;?version=&apos; + version()) &gt; 31| each item in theme.cdn.css 32| if item !== undefined 33| link(rel=&apos;stylesheet&apos;, href=item + &apos;?version=&apos; + version()) 34| include ./head.pugCannot read property &apos;css&apos; of undefined at eval (eval at wrap (/home/hgneer/Hexo/node_modules/pug-runtime/wrap.js:6:10), &lt;anonymous&gt;:80:25) at eval (eval at wrap (/home/hgneer/Hexo/node_modules/pug-runtime/wrap.js:6:10), &lt;anonymous&gt;:102:4) at template (eval at wrap (/home/hgneer/Hexo/node_modules/pug-runtime/wrap.js:6:10), &lt;anonymous&gt;:1657:72) at Theme._View.View._compiled.locals [as _compiled] (/home/hgneer/Hexo/node_modules/hexo/lib/theme/view.js:125:48) at Theme._View.View.View.render (/home/hgneer/Hexo/node_modules/hexo/lib/theme/view.js:30:15) at route.set (/home/hgneer/Hexo/node_modules/hexo/lib/hexo/index.js:394:29) at tryCatcher (/home/hgneer/Hexo/node_modules/bluebird/js/release/util.js:16:23) at /home/hgneer/Hexo/node_modules/bluebird/js/release/method.js:15:34 at RouteStream._read (/home/hgneer/Hexo/node_modules/hexo/lib/hexo/router.js:134:3) at RouteStream.Readable.read (_stream_readable.js:452:10) at resume_ (_stream_readable.js:899:12) at process._tickCallback (internal/process/next_tick.js:63:19) 解决办法需要复制到Hexo/source/_data下的_config.yml是melody主题目录下的而非Hexo目录下的。 待用特性 Slide页面(利用reveal.js) 相册页面","categories":[{"name":"编码笔记","slug":"编码笔记","permalink":"https://AIpynux.github.io/categories/编码笔记/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://AIpynux.github.io/tags/Hexo/"}]},{"title":"可选发型","slug":"可选发型","date":"2019-01-31T08:53:55.000Z","updated":"2019-02-03T08:46:27.913Z","comments":true,"path":"2019/01/31/可选发型/","link":"","permalink":"https://AIpynux.github.io/2019/01/31/可选发型/","excerpt":"","text":"短发 板寸 碎发 莫西干 中发 复古油头","categories":[{"name":"生活笔记","slug":"生活笔记","permalink":"https://AIpynux.github.io/categories/生活笔记/"}],"tags":[]},{"title":"为Github账户设置GPG认证","slug":"为Github账户设置GPG认证","date":"2019-01-31T06:28:35.000Z","updated":"2019-02-04T04:11:18.069Z","comments":true,"path":"2019/01/31/为Github账户设置GPG认证/","link":"","permalink":"https://AIpynux.github.io/2019/01/31/为Github账户设置GPG认证/","excerpt":"概述GPG密钥算法旨在完成文件传输过程中的加密工作。 Github支持的GPG密钥算法: RSA ElGamal DSA ECDH ECDSA EdDSA 为Github账户设置GPG认证的好处: 可以限制使得对项目的commit必须经过认证后才能merge。 让项目使用者明晰哪些commit是官方认证哪些又是未经许可。","text":"概述GPG密钥算法旨在完成文件传输过程中的加密工作。 Github支持的GPG密钥算法: RSA ElGamal DSA ECDH ECDSA EdDSA 为Github账户设置GPG认证的好处: 可以限制使得对项目的commit必须经过认证后才能merge。 让项目使用者明晰哪些commit是官方认证哪些又是未经许可。 查看已有GPG密钥1gpg --list-secret-keys --keyid-format LONG 创建GPG密钥1gpg --gen-key 添加密钥到Github账户查看已创建的密钥，从中选择要添加到Github的密钥ID是6DD5E93799EE33C7。 12345678910$ gpg --list-secret-keys --keyid-format LONG/home/hgneer/.gnupg/secring.gpg-------------------------------sec 2048R/BCA9B4B1BA4C13CE 2017-04-05uid HeGuang (GPG key for HeGuang) &lt;hgneer@gmail.com&gt;ssb 2048R/D0B0CD73B2553FBB 2017-04-05sec 4096R/6DD5E93799EE33C7 2019-01-31uid AIpynux (New World!) &lt;AIpynux@gmail.com&gt;ssb 4096R/2C344A43117B0512 2019-01-31 使用如下命令将ID是6DD5E93799EE33C7的密钥的公钥输出到终端显示。 1gpg --armor --export 6DD5E93799EE33C7 之后将得到的像下面格式一样的文本复制Github账户的GPG密钥设置框。 —–BEGIN PGP PUBLIC KEY BLOCK—–公钥内容—–END PGP PUBLIC KEY BLOCK—–. 为本地Git设置全局GPG密钥ID1git config --global user.signingkey 6DD5E93799EE33C7 参考链接 GPG入门教程 Managing commit signature verification","categories":[{"name":"编码笔记","slug":"编码笔记","permalink":"https://AIpynux.github.io/categories/编码笔记/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://AIpynux.github.io/tags/Git/"},{"name":"GPG","slug":"GPG","permalink":"https://AIpynux.github.io/tags/GPG/"}]},{"title":"Vim无插件实现Markdown预览","slug":"Vim无插件Markdown预览","date":"2019-01-20T06:58:53.000Z","updated":"2019-02-02T04:11:50.005Z","comments":true,"path":"2019/01/20/Vim无插件Markdown预览/","link":"","permalink":"https://AIpynux.github.io/2019/01/20/Vim无插件Markdown预览/","excerpt":"环境 chromium-browser Markdown Viewer Ubuntu16.04 Vim","text":"环境 chromium-browser Markdown Viewer Ubuntu16.04 Vim 步骤 确保chromium-browser可以从终端输入命令启动。 为chromium安装Markdown Viewer插件 在~/.vimrc中添加如下代码: 123456nmap &lt;F4&gt; :call Preview()&lt;CR&gt;func! Preview() if &amp;filetype == &apos;markdown.mkd&apos; exec &quot;!chromium-browser %&quot; endifendfunc 效果用Vim编辑Markdown文件时按F4会打开一个chromium窗口进行预览,每次保存文件时更新预览。 注意不要用Firefox，Firefox自动对离线文件的编码解析总不准确且不能修改默认的离线文件编码为Unicode，所以总是造成乱码。 参考Vim无插件实现Markdown文件实时预览","categories":[{"name":"Tools","slug":"Tools","permalink":"https://AIpynux.github.io/categories/Tools/"},{"name":"Vim","slug":"Tools/Vim","permalink":"https://AIpynux.github.io/categories/Tools/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://AIpynux.github.io/tags/Vim/"}]},{"title":"Improve the Speed of Git Clone from Github","slug":"Improve_the_Speed_of_Git_Clone_from_Github","date":"2019-01-20T06:57:53.000Z","updated":"2019-02-04T04:22:54.285Z","comments":true,"path":"2019/01/20/Improve_the_Speed_of_Git_Clone_from_Github/","link":"","permalink":"https://AIpynux.github.io/2019/01/20/Improve_the_Speed_of_Git_Clone_from_Github/","excerpt":"出现障碍更新Vim到8.1后检查插件状态，发现ale需要重新安装。 用的插件管理器是Vim-Plug，在.vimrc.bundles中添加: 1Plug &apos;w0rp/ale&apos; 之后在Vim中执行命令 :PlugInstall 看着屏幕上的进度条一点点地跑到终点，终端却抛来如下错误:","text":"出现障碍更新Vim到8.1后检查插件状态，发现ale需要重新安装。 用的插件管理器是Vim-Plug，在.vimrc.bundles中添加: 1Plug &apos;w0rp/ale&apos; 之后在Vim中执行命令 :PlugInstall 看着屏幕上的进度条一点点地跑到终点，终端却抛来如下错误: 1234error: RPC failed; curl 18 transfer closed with outstanding read data remainingfatal: The remote end hung up unexpectedlyfatal: early EOFfatal: index-pack failed 分析原因看上诉错误的字面意思是下载的包在传输过程中提前结束。我以为凑巧出错便重新下载。 经过实验多次，这样的错误发生不是偶然。之后,经过查阅文档,我发现Vim-Plug实际上采 用git来下载安装Github上的插件项目。然而,国内用终端克隆Github上Repository速度特慢, 猜测此次障碍可能由此造成。 解决办法1. 为git设置代理在设置了SS代理的前提下，从终端输入: 12git config --global http.https://github.com.proxy socks5://127.0.0.1:1080git config --global https.https://github.com.proxy socks5://127.0.0.1:1080 2. 修改Hosts用以下命令查找github.global.ssl.fastly.Net和github.com对应的IP地址:12nslookup github.global.ssl.fastly.Netnslookup github.com 之后将IP地址和域名对添加到/etc/hosts文件。 最终效果git clone的速度从10.0KB/s提升到150.0KB/s;出现的插件下载安装障碍得到解决。 参考文章git clone速度太慢解决方案 git clone一个github上的仓库，太慢…","categories":[{"name":"Tools","slug":"Tools","permalink":"https://AIpynux.github.io/categories/Tools/"},{"name":"Git","slug":"Tools/Git","permalink":"https://AIpynux.github.io/categories/Tools/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://AIpynux.github.io/tags/Git/"}]},{"title":"Ubuntu16.04备份重装成根目录可扩容LVM方式Linux系统","slug":"Ubuntu16.04备份重装成根目录可扩容的LVM方式Linux系统","date":"2019-01-20T06:56:53.000Z","updated":"2019-02-04T01:57:19.880Z","comments":true,"path":"2019/01/20/Ubuntu16.04备份重装成根目录可扩容的LVM方式Linux系统/","link":"","permalink":"https://AIpynux.github.io/2019/01/20/Ubuntu16.04备份重装成根目录可扩容的LVM方式Linux系统/","excerpt":"说明:为了区分原先系统和重装后系统以及述说方便，将原先系统称作Ubuntu1，重装后系统称作Ubuntu2。 先看一下我Ubuntu1的一些信息：","text":"说明:为了区分原先系统和重装后系统以及述说方便，将原先系统称作Ubuntu1，重装后系统称作Ubuntu2。 先看一下我Ubuntu1的一些信息： 一、备份进入Ubuntu1，输入su root切换root，将设备/dev/sdb1（选一个你机器上有空余空间未挂载的分区）挂载到/tmp。终端输入tar -cvpzf /tmp/back/back.tgz / –exclude=/proc –exclude=/lost+found –exclude=/tmp –exclude=/sys –exclude=/media。将Ubuntu1上所有挂载在/目录下的文件(除了/目录下proc、lost+found、tmp、sys和media文件夹)压缩在已挂载/dev/sdb1设备的目录/tmp的back文件夹下，并命名为back.tgz。 12345注意：1. /tmp下的back文件夹须事先创建。2. 备份时勿包括/dev/sdb1所挂载的目录（此处为/tmp）。3. 记下那些备份时未包括进来的目录（即proc等），最后恢复时需要手动mkdir创建，否则系统会出错。4. 最后压缩结束后可能会出现 tar: 由于前次错误，将以上次的错误状态退出。这个不用理会即可。 二、分配磁盘右击此电脑–&gt;管理 得到计算机管理窗口–&gt;点击磁盘管理–&gt;右键单击选择要压缩的磁盘 在输入压缩空间量（MB）里填写要压缩出的空间量,我这里压缩50G–&gt;压缩 注：这里得到未分配的磁盘为待会我们用Linux进行LVM式分区做准备。(电脑若有有空闲空间的设备直接跳过此步骤到第三步进行分区） 三、分区制作Ubuntu16.04的U盘启动盘，进入试用即LiveCD模式。首先在终端输入sudo passwd root，改变试用系统下root用户的密码。之后输入su root切换成root用户，之后的大多操作都需要root权限。 终端输入fdisk -l找到划分好有空闲空间的磁盘设备名。 我主机上有未分配磁盘空间的设备是/dev/sdb。所以终端输入fdisk /dev/sdb。输入n新建一个分区(/dev/sdb6)。分区号为6–&gt;分区起始扇区按回车默认设置–&gt;分区终结扇区输入+49G，代表起始扇区往后数49G的扇区，意味给分区分配49G。此分区待会制成lv时会分成给Ubuntu2的/、swap交换空间和/home对应的三个lv分区，此时先成一个就好,但需将分区类型标志改成LVM。 输入t改变分区标志–&gt;分区号为6–&gt;输入L查找代表LVM的代码–&gt;查得30代表LVM，输入30，修改标志成功。 输入n新建另一个分区(sdb7)对应给Ubuntu2的/boot，分配剩下的1G给此分区，此分区不需要改成LVM，不改标志。 输入p查看分区是否正确，确认无误后输入w写入并退出fdisk。 终端输入partprobe更新分区信息。再输入fdisk -l /dev/sdb查看分区创建成功否。 四、创建PV、VG、LV终端输入pvcreate /dev/sdb6创建pv，输入pvscan查看目前有哪些pv检查创建成功否。终端输入vgcreate hgneer1 /dev/sdb6创建名字为hgneer1（随自己定义的名字）的vg，输入vgscan查看目前有哪些pv检查创建成功否。终端输入lvcreate -L +25G -n root hgneer1（刚才创建的vg），表示创建一个大小为25G的/dev/mapper/hgneer1-root的lv分区，预定作为Ubuntu2的/对应的分区。终端输入lvcreate -L +8G -n swap hgneer1（刚才创建的vg），表示创建一个大小为8G的/dev/mapper/hgneer1-swap的lv分区，预定作为Ubuntu2的swap交换空间对应的分区。终端输入lvcreate -L +16G -n home hgneer1（刚才创建的vg），表示创建一个大小为16G的/dev/mapper/hgneer1-home的lv分区，预定作为Ubuntu2的/home对应的分区。终端输入lvscan检查所需lv创建成功否。确认无误后，lvm分区真正创建。 五、重装系统点击桌面上的“install Ubuntu16.04.3 LTS”开始安装 安装时选择其他选项，自行分区选择调整。/dev/mapper/hgneer1-home分区挂载到/home目录，选中格式化成Ext4日志文件系统/dev/mapper/hgneer1-root分区挂载到/目录，选中格式化成Ext4日志文件系统/dev/mapper/hgneer1-swap分区作为swap交换空间/dev/sdb7分区挂载到/boot目录，选中格式化成Ext4日志文件系统另外注意安装启动引导器的设备选择挂载到/boot目录的/dev/sdb7，否则很可能无法引导出Linux系统！！！ 等待安装成功后，先不要重启，继续试用，看新装上的系统Ubuntu2是否使用了LVM。终端输入mount /dev/mapper/hgneer-root /mnt挂载Ubuntu2的/到试用系统的/mnt。终端输入mount /dev/mapper/hgneer-home /mnt/home挂载Ubuntu2的/home到试用系统的/mnt/home。终端输入mount /dev/sdb7 /mnt挂载Ubuntu2的/boot到试用系统的/mnt/boot。cd到上面几个目录下看下，确定不为空系统成功装上后终端输入chroot /mnt将/mnt改成根目录，而后关机。 六、恢复数据及配置重启进入Ubuntu2系统。将/etc/fstab文件及/boot目录备份到挂载了/dev/sdb1的/tmp的back文件夹中。这些文件记载了Ubuntu2的启动信息以及Ubuntu2各重要目录所在的分区信息，这些文件与Ubuntu1不一样的因此在之后解压备份文件后需要把这些文件替换到对应目录下。 重启进入liveCD（U盘启动盘试用）。照前文一样命令获取试用系统的root权限。 终端输入mount /dev/mapper/hgneer-root /mnt挂载Ubuntu2的/到试用系统的/mnt。 终端输入mount /dev/mapper/hgneer-home /mnt/home挂载Ubuntu2的/home到试用系统的/mnt/home。 终端输入mount /dev/sdb7 /mnt/boot挂载Ubuntu2的/boot到试用系统的/mnt/boot。 cd到/mnt目录后，终端输入ls | xargs rm -rf，删除Ubuntu2系统根目录下的全部目录及文件。 终端输入mount /dev/sdb1 /tmp挂载D盘到/tmp目录，cd到/tmp/back后终端输入tar -xvpf back.tgz -C /mnt。 最终目的将Ubuntu1的备份下数据文件解压到/mnt即Ubuntu2的根目录下。 等到解压完成后cd到/mnt后，终端输入mkdir proc lost+found tmp sys media，创建Ubuntu1备份时未选中的目录。将备份在设备/dev/sdb1即现挂载在/tmp目录下的back文件夹中的fstab拷贝替换到/mnt/etc目录下。将备份在设备/dev/sdb1即现挂载在/tmp目录下的back文件夹中的/boot文件夹中的文件拷贝到/mnt/boot目录下。终端输入chroot /mnt转换/mnt当作根目录。重启进入Ubuntu2，根目录可扩容且用户数据配置与Ubuntu1完全一致的Linux系统完成！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://AIpynux.github.io/categories/Linux/"},{"name":"Ubuntu","slug":"Linux/Ubuntu","permalink":"https://AIpynux.github.io/categories/Linux/Ubuntu/"},{"name":"磁盘阵列","slug":"磁盘阵列","permalink":"https://AIpynux.github.io/categories/磁盘阵列/"},{"name":"LVM","slug":"磁盘阵列/LVM","permalink":"https://AIpynux.github.io/categories/磁盘阵列/LVM/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://AIpynux.github.io/tags/Ubuntu/"}]}]}